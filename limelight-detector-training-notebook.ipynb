{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJVo_xMPf4LY"
      },
      "source": [
        "![TrainingNotebookLogo.png](https://downloads.limelightvision.io/content/TrainingNotebookLogo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72xbzFQrPL5q"
      },
      "source": [
        "To train a neural object detector for Limelight, click the \"play\" button on each code block. Pay extra attention to any \"❗\" you see. By the end of this tutorial, you will have downloaded a .zip file containing your model and label files.\n",
        "\n",
        "See https://docs.limelightvision.io/docs/docs-limelight/pipeline-neural/training-your-own-detector for a more in-depth tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05N8FeXHcQp3"
      },
      "source": [
        "# 1. Install The Object Detection Package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypWGYdPlLRUN"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "tmpModelPath ='/content/models'\n",
        "if os.path.exists(tmpModelPath) and os.path.isdir(tmpModelPath):\n",
        "  shutil.rmtree(tmpModelPath)\n",
        "\n",
        "MLENVIRONMENT=\"COLAB\"\n",
        "!git clone --depth 1 https://github.com/tensorflow/models\n",
        "!cd models && git fetch --depth 1 origin ad1f7b56943998864db8f5db0706950e93bb7d81 && git checkout ad1f7b56943998864db8f5db0706950e93bb7d81"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QPmVBSlLTzM"
      },
      "outputs": [],
      "source": [
        "# Environment Setup\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "\n",
        "print(sys.version)\n",
        "if(MLENVIRONMENT == \"COLAB\"):\n",
        "    print(\"colab env setup\")\n",
        "    os.environ[\"HOMEFOLDER\"] = \"/content/\"\n",
        "    HOMEFOLDER = '{HOMEFOLDER}'.format(**os.environ)\n",
        "    FINALOUTPUTFOLDER_DIRNAME = 'final_output'\n",
        "    FINALOUTPUTFOLDER = HOMEFOLDER+FINALOUTPUTFOLDER_DIRNAME\n",
        "    print(HOMEFOLDER)\n",
        "\n",
        "# Copy setup files into models/research folder\n",
        "!cd {HOMEFOLDER}models/research && pwd && protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Modify setup.py\n",
        "with open(HOMEFOLDER+'models/research/object_detection/packages/tf2/setup.py') as f:\n",
        "    s = f.read()\n",
        "\n",
        "with open(HOMEFOLDER+'models/research/setup.py', 'w') as f:\n",
        "    if(MLENVIRONMENT == \"COLAB\"):\n",
        "        s = re.sub('tf-models-official>=2.5.1','tf-models-official==2.15.0', s)\n",
        "        f.write(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLDnCkLLwLr6"
      },
      "outputs": [],
      "source": [
        "# Install\n",
        "!pip install {HOMEFOLDER}models/research/\n",
        "if(MLENVIRONMENT == \"COLAB\"):\n",
        "    !pip install tensorflow==2.15.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V7TrfUos-9E"
      },
      "source": [
        "Test the environment by running `model_builder_tf2_test.py` to make sure everything is working as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh_HPMOqWH9z"
      },
      "outputs": [],
      "source": [
        "!python {HOMEFOLDER}models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmROIG9zaS9G"
      },
      "source": [
        "#2. Get Dataset From Google Drive\n",
        "\n",
        "❗Using the same Google account you are using for this Colab, upload your RoboFlow .tfrecord.zip to your Google Drive. Some input is required in this section❗"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvtPNjlCHTpO"
      },
      "source": [
        "This code block will mount your entire Google Drive in the \"Files\" pane on the left-hand side of your screen.\n",
        "\n",
        "❗Click the Refresh button in the \"Files\" pane after running the code block.❗"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLgAPsQsfTLs"
      },
      "outputs": [],
      "source": [
        "if(MLENVIRONMENT==\"COLAB\"):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLBxE6xo52-k"
      },
      "source": [
        "❗ Run the code block, wait for the file selection interface to appear, and select your .tfrecord.zip dataset ❗\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Klf4ZkYy2Mw8"
      },
      "outputs": [],
      "source": [
        "from ipyfilechooser import FileChooser\n",
        "fc = FileChooser('/content/')\n",
        "display(fc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2EboTT5owV_"
      },
      "source": [
        "\n",
        "\n",
        "Unzip the selected dataset into the session's filesystem.\n",
        "\n",
        "❗Click the Refresh button after running the code block.❗\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPtKVTufFG4C"
      },
      "outputs": [],
      "source": [
        "if(MLENVIRONMENT==\"COLAB\"):\n",
        "    datasetPath = '\\''+fc.selected+ '\\''\n",
        "    print(datasetPath)\n",
        "    !unzip $datasetPath"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6kMXxVJo5za"
      },
      "source": [
        "Auto-detect relevant tfrecord components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUd2wtfrqedy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def find_files(directory, pattern):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for basename in files:\n",
        "            if fnmatch.fnmatch(basename, pattern):\n",
        "                filename = os.path.join(root, basename)\n",
        "                yield filename\n",
        "\n",
        "def set_tfrecord_variables(directory):\n",
        "    train_record_fname = ''\n",
        "    val_record_fname = ''\n",
        "    label_map_pbtxt_fname = ''\n",
        "\n",
        "    for tfrecord_file in find_files(directory, '*.tfrecord'):\n",
        "        if '/train/' in tfrecord_file:\n",
        "            train_record_fname = tfrecord_file\n",
        "        elif '/valid/' in tfrecord_file:\n",
        "            val_record_fname = tfrecord_file\n",
        "        elif '/test/' in tfrecord_file:\n",
        "            pass\n",
        "\n",
        "    for label_map_file in find_files(directory, '*_label_map.pbtxt'):\n",
        "        label_map_pbtxt_fname = label_map_file  # Assuming one common label map file\n",
        "\n",
        "    return train_record_fname, val_record_fname, label_map_pbtxt_fname\n",
        "\n",
        "train_record_fname, val_record_fname, label_map_pbtxt_fname = set_tfrecord_variables('/content')\n",
        "\n",
        "#if(MLENVIRONMENT==\"COLAB\"):\n",
        "    #train_record_fname = '/content/train/cubes-cones.tfrecord'\n",
        "    #val_record_fname = '/content/valid/cubes-cones.tfrecord'\n",
        "    #label_map_pbtxt_fname = '/content/train/cubes-cones_label_map.pbtxt'\n",
        "\n",
        "print(\"Train Record File:\", train_record_fname)\n",
        "print(\"Validation Record File:\", val_record_fname)\n",
        "print(\"Label Map File:\", label_map_pbtxt_fname)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGEUZYAMEZ6f"
      },
      "source": [
        "# 3.&nbsp;Training Configuration and Labels File Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2MAcgJ53STW"
      },
      "source": [
        "Download the pre-trained Limelight Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN0EUEa3e5Un"
      },
      "outputs": [],
      "source": [
        "chosen_model = 'ssd-mobilenet-v2'\n",
        "MODELS_CONFIG = {\n",
        "    'ssd-mobilenet-v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "}\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "\n",
        "# Create \"mymodel\" folder for pre-trained weights and configuration files\n",
        "%cd ~\n",
        "%mkdir {HOMEFOLDER}models/mymodel/\n",
        "%cd {HOMEFOLDER}models/mymodel/\n",
        "%pwd\n",
        "\n",
        "# Download pre-trained model weights\n",
        "import tarfile\n",
        "download_tar = 'https://downloads.limelightvision.io/models/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Download training configuration file for model\n",
        "download_config = 'https://downloads.limelightvision.io/models/' + base_pipeline_file\n",
        "!wget {download_config}\n",
        "%cd ~\n",
        "\n",
        "# Set training parameters for the model\n",
        "num_steps = 40000\n",
        "checkpoint_every = 2000\n",
        "batch_size = 16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMbr89qqgTVW"
      },
      "source": [
        "Generate Labels File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDyH_i3MgP1D"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set file locations and get number of classes for config file\n",
        "pipeline_fname = HOMEFOLDER+'models/mymodel/' + base_pipeline_file\n",
        "fine_tune_checkpoint = HOMEFOLDER+'models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "\n",
        "def get_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "    class_names = [category['name'] for category in category_index.values()]\n",
        "    return class_names\n",
        "\n",
        "def create_label_file(filename, labels):\n",
        "    with open(filename, 'w') as file:\n",
        "        for label in labels:\n",
        "            file.write(label + '\\n')\n",
        "\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "classes = get_classes(label_map_pbtxt_fname)\n",
        "\n",
        "print('Total classes:', num_classes)\n",
        "print(classes)\n",
        "\n",
        "\n",
        "#Generate labels file\n",
        "create_label_file(HOMEFOLDER + \"limelight_neural_detector_labels.txt\", classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwPyaIAXxyKu"
      },
      "source": [
        "Modify the base Limelight Model Configuration File\n",
        "\n",
        "Augmentation Options: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eA5ht3_yukT"
      },
      "outputs": [],
      "source": [
        "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "import re\n",
        "\n",
        "print('writing custom configuration file')\n",
        "\n",
        "\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # Set tfrecord files for train and test datasets\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
        "\n",
        "    # Set label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set batch_size\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes\n",
        "    s = re.sub('checkpoint_every_n: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "\n",
        "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "\n",
        "    # If using ssd-mobilenet-v2, reduce learning rate\n",
        "    if chosen_model == 'ssd-mobilenet-v2':\n",
        "      s = re.sub('learning_rate_base: .8',\n",
        "                 'learning_rate_base: .004', s)\n",
        "\n",
        "      s = re.sub('warmup_learning_rate: 0.13333',\n",
        "                 'warmup_learning_rate: .0016666', s)\n",
        "\n",
        "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
        "    if chosen_model == 'efficientdet-d0':\n",
        "      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
        "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
        "      s = re.sub('min_dimension', 'height', s)\n",
        "      s = re.sub('max_dimension', 'width', s)\n",
        "\n",
        "    f.write(s)\n",
        "\n",
        "# (Optional) Display the custom configuration file's contents\n",
        "# !cat pipeline_file.config\n",
        "# Set the path to the custom config file and the directory to store training checkpoints in\n",
        "pipeline_file = 'pipeline_file.config'\n",
        "model_dir = HOMEFOLDER+'training_progress/'\n",
        "print(\" \")\n",
        "print(model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-19zML6oEO7l"
      },
      "source": [
        "# 4.&nbsp;Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxPj_QV43qD5"
      },
      "source": [
        "Once training starts, come back and click the refresh button within the tensorboard window to check training progress.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI9iCCxoNlAL"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training_progress/train'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejo07C1zXHzY"
      },
      "source": [
        "Fix TF 2.15 breaking changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ltvi224axv3Y"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import re\n",
        "\n",
        "original_path = '/usr/local/lib/python3.10/dist-packages/tf_slim/data/tfexample_decoder.py'\n",
        "with open(original_path, 'r') as file:\n",
        "  content = file.read()\n",
        "  content = re.sub(r'import abc', 'import tensorflow as tf\\n\\nimport abc', content)\n",
        "  content = re.sub(r'control_flow_ops.case', 'tf.case', content)\n",
        "  content = re.sub(r'control_flow_ops.cond', 'tf.compat.v1.cond', content)\n",
        "with open(original_path, 'w') as file:\n",
        "  file.write(content)\n",
        "\n",
        "print(f\"File {original_path} fixed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjqYo9r9ffVx"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQTfZChVzzpZ",
        "outputId": "a0b4606c-8d35-472e-f689-a4cdd2df6fe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-03 03:49:35.572073: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-03 03:49:35.577118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-03 03:49:35.578735: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-03 03:49:37.405189: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_main_tf2.py:100: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use distribute.MultiWorkerMirroredStrategy instead\n",
            "W1103 03:49:41.187359 138844351791744 deprecation.py:50] From /content/models/research/object_detection/model_main_tf2.py:100: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use distribute.MultiWorkerMirroredStrategy instead\n",
            "2024-11-03 03:49:41.294031: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/device:GPU:0',)\n",
            "I1103 03:49:41.316727 138844351791744 mirrored_strategy.py:423] Using MirroredStrategy with devices ('/device:GPU:0',)\n",
            "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n",
            "I1103 03:49:41.316981 138844351791744 collective_all_reduce_strategy.py:446] Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 40000\n",
            "I1103 03:49:41.320655 138844351791744 config_util.py:552] Maybe overwriting train_steps: 40000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1103 03:49:41.320816 138844351791744 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1103 03:49:41.363159 138844351791744 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/train/samples.tfrecord']\n",
            "I1103 03:49:41.370404 138844351791744 dataset_builder.py:162] Reading unweighted datasets: ['/content/train/samples.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/train/samples.tfrecord']\n",
            "I1103 03:49:41.370612 138844351791744 dataset_builder.py:79] Reading record datasets for input file: ['/content/train/samples.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1103 03:49:41.370697 138844351791744 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1103 03:49:41.370773 138844351791744 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1103 03:49:41.377101 138844351791744 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1103 03:49:41.396330 138844351791744 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1103 03:49:47.445110 138844351791744 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1103 03:49:50.724522 138844351791744 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1103 03:49:55.079010 138844351791744 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2024-11-03 03:49:58.442071: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 34773504 bytes after encountering the first element of size 34773504 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I1103 03:50:03.612822 138839560549952 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1103 03:50:05.330802 138839560549952 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1103 03:50:05.331132 138839560549952 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1103 03:50:05.331297 138839560549952 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1103 03:50:05.331429 138839560549952 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1103 03:50:05.331563 138839560549952 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1103 03:50:05.331700 138839560549952 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "I1103 03:50:14.927884 138839560549952 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "I1103 03:50:31.395537 138840337524288 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "I1103 03:50:40.012778 138840337524288 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "I1103 03:50:46.981885 138840337524288 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "I1103 03:50:54.759780 138840337524288 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "2024-11-03 03:51:08.648538: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 34773504 bytes after encountering the first element of size 34773504 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
            "INFO:tensorflow:Step 100 per-step time 0.607s\n",
            "I1103 03:51:30.704286 138844351791744 model_lib_v2.py:705] Step 100 per-step time 0.607s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.39996853,\n",
            " 'Loss/localization_loss': 0.2615056,\n",
            " 'Loss/regularization_loss': 0.08807836,\n",
            " 'Loss/total_loss': 0.7495525,\n",
            " 'learning_rate': 0.00178327}\n",
            "I1103 03:51:30.704660 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.39996853,\n",
            " 'Loss/localization_loss': 0.2615056,\n",
            " 'Loss/regularization_loss': 0.08807836,\n",
            " 'Loss/total_loss': 0.7495525,\n",
            " 'learning_rate': 0.00178327}\n",
            "INFO:tensorflow:Step 200 per-step time 0.144s\n",
            "I1103 03:51:45.083976 138844351791744 model_lib_v2.py:705] Step 200 per-step time 0.144s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23054722,\n",
            " 'Loss/localization_loss': 0.2670525,\n",
            " 'Loss/regularization_loss': 0.088087745,\n",
            " 'Loss/total_loss': 0.58568746,\n",
            " 'learning_rate': 0.0018999401}\n",
            "I1103 03:51:45.084594 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.23054722,\n",
            " 'Loss/localization_loss': 0.2670525,\n",
            " 'Loss/regularization_loss': 0.088087745,\n",
            " 'Loss/total_loss': 0.58568746,\n",
            " 'learning_rate': 0.0018999401}\n",
            "INFO:tensorflow:Step 300 per-step time 0.145s\n",
            "I1103 03:51:59.559071 138844351791744 model_lib_v2.py:705] Step 300 per-step time 0.145s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22115025,\n",
            " 'Loss/localization_loss': 0.24481976,\n",
            " 'Loss/regularization_loss': 0.08809034,\n",
            " 'Loss/total_loss': 0.55406034,\n",
            " 'learning_rate': 0.00201661}\n",
            "I1103 03:51:59.559470 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.22115025,\n",
            " 'Loss/localization_loss': 0.24481976,\n",
            " 'Loss/regularization_loss': 0.08809034,\n",
            " 'Loss/total_loss': 0.55406034,\n",
            " 'learning_rate': 0.00201661}\n",
            "INFO:tensorflow:Step 400 per-step time 0.146s\n",
            "I1103 03:52:14.177649 138844351791744 model_lib_v2.py:705] Step 400 per-step time 0.146s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3099832,\n",
            " 'Loss/localization_loss': 0.33313823,\n",
            " 'Loss/regularization_loss': 0.08808831,\n",
            " 'Loss/total_loss': 0.73120975,\n",
            " 'learning_rate': 0.00213328}\n",
            "I1103 03:52:14.178015 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.3099832,\n",
            " 'Loss/localization_loss': 0.33313823,\n",
            " 'Loss/regularization_loss': 0.08808831,\n",
            " 'Loss/total_loss': 0.73120975,\n",
            " 'learning_rate': 0.00213328}\n",
            "INFO:tensorflow:Step 500 per-step time 0.146s\n",
            "I1103 03:52:28.797174 138844351791744 model_lib_v2.py:705] Step 500 per-step time 0.146s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1900872,\n",
            " 'Loss/localization_loss': 0.17169917,\n",
            " 'Loss/regularization_loss': 0.08808593,\n",
            " 'Loss/total_loss': 0.4498723,\n",
            " 'learning_rate': 0.00224995}\n",
            "I1103 03:52:28.797550 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.1900872,\n",
            " 'Loss/localization_loss': 0.17169917,\n",
            " 'Loss/regularization_loss': 0.08808593,\n",
            " 'Loss/total_loss': 0.4498723,\n",
            " 'learning_rate': 0.00224995}\n",
            "INFO:tensorflow:Step 600 per-step time 0.147s\n",
            "I1103 03:52:43.425164 138844351791744 model_lib_v2.py:705] Step 600 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15068536,\n",
            " 'Loss/localization_loss': 0.07234437,\n",
            " 'Loss/regularization_loss': 0.08808017,\n",
            " 'Loss/total_loss': 0.3111099,\n",
            " 'learning_rate': 0.00236662}\n",
            "I1103 03:52:43.425485 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.15068536,\n",
            " 'Loss/localization_loss': 0.07234437,\n",
            " 'Loss/regularization_loss': 0.08808017,\n",
            " 'Loss/total_loss': 0.3111099,\n",
            " 'learning_rate': 0.00236662}\n",
            "INFO:tensorflow:Step 700 per-step time 0.146s\n",
            "I1103 03:52:58.010795 138844351791744 model_lib_v2.py:705] Step 700 per-step time 0.146s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1338268,\n",
            " 'Loss/localization_loss': 0.15411344,\n",
            " 'Loss/regularization_loss': 0.0880739,\n",
            " 'Loss/total_loss': 0.37601417,\n",
            " 'learning_rate': 0.0024832902}\n",
            "I1103 03:52:58.011145 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.1338268,\n",
            " 'Loss/localization_loss': 0.15411344,\n",
            " 'Loss/regularization_loss': 0.0880739,\n",
            " 'Loss/total_loss': 0.37601417,\n",
            " 'learning_rate': 0.0024832902}\n",
            "INFO:tensorflow:Step 800 per-step time 0.148s\n",
            "I1103 03:53:12.816639 138844351791744 model_lib_v2.py:705] Step 800 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19408812,\n",
            " 'Loss/localization_loss': 0.10227833,\n",
            " 'Loss/regularization_loss': 0.08806468,\n",
            " 'Loss/total_loss': 0.38443112,\n",
            " 'learning_rate': 0.0025999602}\n",
            "I1103 03:53:12.816936 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.19408812,\n",
            " 'Loss/localization_loss': 0.10227833,\n",
            " 'Loss/regularization_loss': 0.08806468,\n",
            " 'Loss/total_loss': 0.38443112,\n",
            " 'learning_rate': 0.0025999602}\n",
            "INFO:tensorflow:Step 900 per-step time 0.146s\n",
            "I1103 03:53:27.466274 138844351791744 model_lib_v2.py:705] Step 900 per-step time 0.146s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.112657264,\n",
            " 'Loss/localization_loss': 0.09313028,\n",
            " 'Loss/regularization_loss': 0.088055,\n",
            " 'Loss/total_loss': 0.29384255,\n",
            " 'learning_rate': 0.0027166302}\n",
            "I1103 03:53:27.466610 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.112657264,\n",
            " 'Loss/localization_loss': 0.09313028,\n",
            " 'Loss/regularization_loss': 0.088055,\n",
            " 'Loss/total_loss': 0.29384255,\n",
            " 'learning_rate': 0.0027166302}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.149s\n",
            "I1103 03:53:42.358923 138844351791744 model_lib_v2.py:705] Step 1000 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19356008,\n",
            " 'Loss/localization_loss': 0.11931122,\n",
            " 'Loss/regularization_loss': 0.088043824,\n",
            " 'Loss/total_loss': 0.40091515,\n",
            " 'learning_rate': 0.0028333003}\n",
            "I1103 03:53:42.359251 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.19356008,\n",
            " 'Loss/localization_loss': 0.11931122,\n",
            " 'Loss/regularization_loss': 0.088043824,\n",
            " 'Loss/total_loss': 0.40091515,\n",
            " 'learning_rate': 0.0028333003}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.148s\n",
            "I1103 03:53:57.120299 138844351791744 model_lib_v2.py:705] Step 1100 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19860604,\n",
            " 'Loss/localization_loss': 0.17825902,\n",
            " 'Loss/regularization_loss': 0.088033095,\n",
            " 'Loss/total_loss': 0.46489817,\n",
            " 'learning_rate': 0.0029499703}\n",
            "I1103 03:53:57.120638 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.19860604,\n",
            " 'Loss/localization_loss': 0.17825902,\n",
            " 'Loss/regularization_loss': 0.088033095,\n",
            " 'Loss/total_loss': 0.46489817,\n",
            " 'learning_rate': 0.0029499703}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.148s\n",
            "I1103 03:54:11.967797 138844351791744 model_lib_v2.py:705] Step 1200 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17396727,\n",
            " 'Loss/localization_loss': 0.08229196,\n",
            " 'Loss/regularization_loss': 0.08802289,\n",
            " 'Loss/total_loss': 0.34428212,\n",
            " 'learning_rate': 0.0030666403}\n",
            "I1103 03:54:11.968137 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.17396727,\n",
            " 'Loss/localization_loss': 0.08229196,\n",
            " 'Loss/regularization_loss': 0.08802289,\n",
            " 'Loss/total_loss': 0.34428212,\n",
            " 'learning_rate': 0.0030666403}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.148s\n",
            "I1103 03:54:26.809718 138844351791744 model_lib_v2.py:705] Step 1300 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17008263,\n",
            " 'Loss/localization_loss': 0.09856071,\n",
            " 'Loss/regularization_loss': 0.08800911,\n",
            " 'Loss/total_loss': 0.35665247,\n",
            " 'learning_rate': 0.0031833102}\n",
            "I1103 03:54:26.810030 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.17008263,\n",
            " 'Loss/localization_loss': 0.09856071,\n",
            " 'Loss/regularization_loss': 0.08800911,\n",
            " 'Loss/total_loss': 0.35665247,\n",
            " 'learning_rate': 0.0031833102}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.148s\n",
            "I1103 03:54:41.612837 138844351791744 model_lib_v2.py:705] Step 1400 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17654216,\n",
            " 'Loss/localization_loss': 0.09266041,\n",
            " 'Loss/regularization_loss': 0.08799807,\n",
            " 'Loss/total_loss': 0.35720065,\n",
            " 'learning_rate': 0.0032999802}\n",
            "I1103 03:54:41.613163 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.17654216,\n",
            " 'Loss/localization_loss': 0.09266041,\n",
            " 'Loss/regularization_loss': 0.08799807,\n",
            " 'Loss/total_loss': 0.35720065,\n",
            " 'learning_rate': 0.0032999802}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.147s\n",
            "I1103 03:54:56.303894 138844351791744 model_lib_v2.py:705] Step 1500 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.092636615,\n",
            " 'Loss/localization_loss': 0.03015826,\n",
            " 'Loss/regularization_loss': 0.08798594,\n",
            " 'Loss/total_loss': 0.21078081,\n",
            " 'learning_rate': 0.0034166502}\n",
            "I1103 03:54:56.304297 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.092636615,\n",
            " 'Loss/localization_loss': 0.03015826,\n",
            " 'Loss/regularization_loss': 0.08798594,\n",
            " 'Loss/total_loss': 0.21078081,\n",
            " 'learning_rate': 0.0034166502}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.148s\n",
            "I1103 03:55:11.141993 138844351791744 model_lib_v2.py:705] Step 1600 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14576876,\n",
            " 'Loss/localization_loss': 0.06282896,\n",
            " 'Loss/regularization_loss': 0.08797285,\n",
            " 'Loss/total_loss': 0.29657057,\n",
            " 'learning_rate': 0.0035333203}\n",
            "I1103 03:55:11.142410 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.14576876,\n",
            " 'Loss/localization_loss': 0.06282896,\n",
            " 'Loss/regularization_loss': 0.08797285,\n",
            " 'Loss/total_loss': 0.29657057,\n",
            " 'learning_rate': 0.0035333203}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.150s\n",
            "I1103 03:55:26.154627 138844351791744 model_lib_v2.py:705] Step 1700 per-step time 0.150s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12475275,\n",
            " 'Loss/localization_loss': 0.0456329,\n",
            " 'Loss/regularization_loss': 0.08795768,\n",
            " 'Loss/total_loss': 0.25834334,\n",
            " 'learning_rate': 0.00364999}\n",
            "I1103 03:55:26.157497 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.12475275,\n",
            " 'Loss/localization_loss': 0.0456329,\n",
            " 'Loss/regularization_loss': 0.08795768,\n",
            " 'Loss/total_loss': 0.25834334,\n",
            " 'learning_rate': 0.00364999}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.149s\n",
            "I1103 03:55:41.028189 138844351791744 model_lib_v2.py:705] Step 1800 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07316491,\n",
            " 'Loss/localization_loss': 0.037727688,\n",
            " 'Loss/regularization_loss': 0.08794327,\n",
            " 'Loss/total_loss': 0.19883586,\n",
            " 'learning_rate': 0.00376666}\n",
            "I1103 03:55:41.028592 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.07316491,\n",
            " 'Loss/localization_loss': 0.037727688,\n",
            " 'Loss/regularization_loss': 0.08794327,\n",
            " 'Loss/total_loss': 0.19883586,\n",
            " 'learning_rate': 0.00376666}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.150s\n",
            "I1103 03:55:56.064536 138844351791744 model_lib_v2.py:705] Step 1900 per-step time 0.150s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16262695,\n",
            " 'Loss/localization_loss': 0.10707582,\n",
            " 'Loss/regularization_loss': 0.08792899,\n",
            " 'Loss/total_loss': 0.35763174,\n",
            " 'learning_rate': 0.0038833302}\n",
            "I1103 03:55:56.064899 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.16262695,\n",
            " 'Loss/localization_loss': 0.10707582,\n",
            " 'Loss/regularization_loss': 0.08792899,\n",
            " 'Loss/total_loss': 0.35763174,\n",
            " 'learning_rate': 0.0038833302}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.149s\n",
            "I1103 03:56:10.961977 138844351791744 model_lib_v2.py:705] Step 2000 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21441723,\n",
            " 'Loss/localization_loss': 0.16730402,\n",
            " 'Loss/regularization_loss': 0.087911986,\n",
            " 'Loss/total_loss': 0.46963325,\n",
            " 'learning_rate': 0.004}\n",
            "I1103 03:56:10.962380 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.21441723,\n",
            " 'Loss/localization_loss': 0.16730402,\n",
            " 'Loss/regularization_loss': 0.087911986,\n",
            " 'Loss/total_loss': 0.46963325,\n",
            " 'learning_rate': 0.004}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.158s\n",
            "I1103 03:56:26.830479 138844351791744 model_lib_v2.py:705] Step 2100 per-step time 0.158s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16064124,\n",
            " 'Loss/localization_loss': 0.105450876,\n",
            " 'Loss/regularization_loss': 0.087895334,\n",
            " 'Loss/total_loss': 0.35398746,\n",
            " 'learning_rate': 0.0039999573}\n",
            "I1103 03:56:26.830918 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.16064124,\n",
            " 'Loss/localization_loss': 0.105450876,\n",
            " 'Loss/regularization_loss': 0.087895334,\n",
            " 'Loss/total_loss': 0.35398746,\n",
            " 'learning_rate': 0.0039999573}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.149s\n",
            "I1103 03:56:41.689508 138844351791744 model_lib_v2.py:705] Step 2200 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10917433,\n",
            " 'Loss/localization_loss': 0.056898378,\n",
            " 'Loss/regularization_loss': 0.087879635,\n",
            " 'Loss/total_loss': 0.25395235,\n",
            " 'learning_rate': 0.003999829}\n",
            "I1103 03:56:41.689864 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.10917433,\n",
            " 'Loss/localization_loss': 0.056898378,\n",
            " 'Loss/regularization_loss': 0.087879635,\n",
            " 'Loss/total_loss': 0.25395235,\n",
            " 'learning_rate': 0.003999829}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.148s\n",
            "I1103 03:56:56.492930 138844351791744 model_lib_v2.py:705] Step 2300 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13106267,\n",
            " 'Loss/localization_loss': 0.03839191,\n",
            " 'Loss/regularization_loss': 0.087861836,\n",
            " 'Loss/total_loss': 0.2573164,\n",
            " 'learning_rate': 0.0039996146}\n",
            "I1103 03:56:56.493271 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.13106267,\n",
            " 'Loss/localization_loss': 0.03839191,\n",
            " 'Loss/regularization_loss': 0.087861836,\n",
            " 'Loss/total_loss': 0.2573164,\n",
            " 'learning_rate': 0.0039996146}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.149s\n",
            "I1103 03:57:11.344238 138844351791744 model_lib_v2.py:705] Step 2400 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18448195,\n",
            " 'Loss/localization_loss': 0.070945635,\n",
            " 'Loss/regularization_loss': 0.087841965,\n",
            " 'Loss/total_loss': 0.34326956,\n",
            " 'learning_rate': 0.003999315}\n",
            "I1103 03:57:11.344554 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.18448195,\n",
            " 'Loss/localization_loss': 0.070945635,\n",
            " 'Loss/regularization_loss': 0.087841965,\n",
            " 'Loss/total_loss': 0.34326956,\n",
            " 'learning_rate': 0.003999315}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.148s\n",
            "I1103 03:57:26.116939 138844351791744 model_lib_v2.py:705] Step 2500 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10573476,\n",
            " 'Loss/localization_loss': 0.033256397,\n",
            " 'Loss/regularization_loss': 0.08782588,\n",
            " 'Loss/total_loss': 0.22681703,\n",
            " 'learning_rate': 0.003998929}\n",
            "I1103 03:57:26.117262 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.10573476,\n",
            " 'Loss/localization_loss': 0.033256397,\n",
            " 'Loss/regularization_loss': 0.08782588,\n",
            " 'Loss/total_loss': 0.22681703,\n",
            " 'learning_rate': 0.003998929}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.147s\n",
            "I1103 03:57:40.844377 138844351791744 model_lib_v2.py:705] Step 2600 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12751815,\n",
            " 'Loss/localization_loss': 0.088070296,\n",
            " 'Loss/regularization_loss': 0.0878065,\n",
            " 'Loss/total_loss': 0.30339494,\n",
            " 'learning_rate': 0.003998458}\n",
            "I1103 03:57:40.844692 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.12751815,\n",
            " 'Loss/localization_loss': 0.088070296,\n",
            " 'Loss/regularization_loss': 0.0878065,\n",
            " 'Loss/total_loss': 0.30339494,\n",
            " 'learning_rate': 0.003998458}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.147s\n",
            "I1103 03:57:55.559034 138844351791744 model_lib_v2.py:705] Step 2700 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09344484,\n",
            " 'Loss/localization_loss': 0.03567609,\n",
            " 'Loss/regularization_loss': 0.08778784,\n",
            " 'Loss/total_loss': 0.21690877,\n",
            " 'learning_rate': 0.0039979015}\n",
            "I1103 03:57:55.559367 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.09344484,\n",
            " 'Loss/localization_loss': 0.03567609,\n",
            " 'Loss/regularization_loss': 0.08778784,\n",
            " 'Loss/total_loss': 0.21690877,\n",
            " 'learning_rate': 0.0039979015}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.147s\n",
            "I1103 03:58:10.266004 138844351791744 model_lib_v2.py:705] Step 2800 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11984451,\n",
            " 'Loss/localization_loss': 0.030655427,\n",
            " 'Loss/regularization_loss': 0.08777215,\n",
            " 'Loss/total_loss': 0.2382721,\n",
            " 'learning_rate': 0.0039972593}\n",
            "I1103 03:58:10.266329 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.11984451,\n",
            " 'Loss/localization_loss': 0.030655427,\n",
            " 'Loss/regularization_loss': 0.08777215,\n",
            " 'Loss/total_loss': 0.2382721,\n",
            " 'learning_rate': 0.0039972593}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.147s\n",
            "I1103 03:58:24.944875 138844351791744 model_lib_v2.py:705] Step 2900 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09482412,\n",
            " 'Loss/localization_loss': 0.042505883,\n",
            " 'Loss/regularization_loss': 0.08775363,\n",
            " 'Loss/total_loss': 0.22508362,\n",
            " 'learning_rate': 0.0039965315}\n",
            "I1103 03:58:24.945206 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.09482412,\n",
            " 'Loss/localization_loss': 0.042505883,\n",
            " 'Loss/regularization_loss': 0.08775363,\n",
            " 'Loss/total_loss': 0.22508362,\n",
            " 'learning_rate': 0.0039965315}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.150s\n",
            "I1103 03:58:39.935714 138844351791744 model_lib_v2.py:705] Step 3000 per-step time 0.150s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06441744,\n",
            " 'Loss/localization_loss': 0.014548178,\n",
            " 'Loss/regularization_loss': 0.08773441,\n",
            " 'Loss/total_loss': 0.16670002,\n",
            " 'learning_rate': 0.003995718}\n",
            "I1103 03:58:39.936020 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.06441744,\n",
            " 'Loss/localization_loss': 0.014548178,\n",
            " 'Loss/regularization_loss': 0.08773441,\n",
            " 'Loss/total_loss': 0.16670002,\n",
            " 'learning_rate': 0.003995718}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.148s\n",
            "I1103 03:58:54.720494 138844351791744 model_lib_v2.py:705] Step 3100 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13231812,\n",
            " 'Loss/localization_loss': 0.036576245,\n",
            " 'Loss/regularization_loss': 0.087716,\n",
            " 'Loss/total_loss': 0.25661036,\n",
            " 'learning_rate': 0.0039948192}\n",
            "I1103 03:58:54.720800 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.13231812,\n",
            " 'Loss/localization_loss': 0.036576245,\n",
            " 'Loss/regularization_loss': 0.087716,\n",
            " 'Loss/total_loss': 0.25661036,\n",
            " 'learning_rate': 0.0039948192}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.148s\n",
            "I1103 03:59:09.524746 138844351791744 model_lib_v2.py:705] Step 3200 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1464104,\n",
            " 'Loss/localization_loss': 0.07454832,\n",
            " 'Loss/regularization_loss': 0.087696284,\n",
            " 'Loss/total_loss': 0.30865502,\n",
            " 'learning_rate': 0.003993835}\n",
            "I1103 03:59:09.525062 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.1464104,\n",
            " 'Loss/localization_loss': 0.07454832,\n",
            " 'Loss/regularization_loss': 0.087696284,\n",
            " 'Loss/total_loss': 0.30865502,\n",
            " 'learning_rate': 0.003993835}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.147s\n",
            "I1103 03:59:24.190603 138844351791744 model_lib_v2.py:705] Step 3300 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17296039,\n",
            " 'Loss/localization_loss': 0.095163964,\n",
            " 'Loss/regularization_loss': 0.08767639,\n",
            " 'Loss/total_loss': 0.35580075,\n",
            " 'learning_rate': 0.003992765}\n",
            "I1103 03:59:24.190904 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.17296039,\n",
            " 'Loss/localization_loss': 0.095163964,\n",
            " 'Loss/regularization_loss': 0.08767639,\n",
            " 'Loss/total_loss': 0.35580075,\n",
            " 'learning_rate': 0.003992765}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.146s\n",
            "I1103 03:59:38.793573 138844351791744 model_lib_v2.py:705] Step 3400 per-step time 0.146s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08113696,\n",
            " 'Loss/localization_loss': 0.027960612,\n",
            " 'Loss/regularization_loss': 0.08765594,\n",
            " 'Loss/total_loss': 0.1967535,\n",
            " 'learning_rate': 0.00399161}\n",
            "I1103 03:59:38.796517 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.08113696,\n",
            " 'Loss/localization_loss': 0.027960612,\n",
            " 'Loss/regularization_loss': 0.08765594,\n",
            " 'Loss/total_loss': 0.1967535,\n",
            " 'learning_rate': 0.00399161}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.149s\n",
            "I1103 03:59:53.737188 138844351791744 model_lib_v2.py:705] Step 3500 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11009738,\n",
            " 'Loss/localization_loss': 0.03583437,\n",
            " 'Loss/regularization_loss': 0.087637044,\n",
            " 'Loss/total_loss': 0.23356879,\n",
            " 'learning_rate': 0.0039903694}\n",
            "I1103 03:59:53.737581 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.11009738,\n",
            " 'Loss/localization_loss': 0.03583437,\n",
            " 'Loss/regularization_loss': 0.087637044,\n",
            " 'Loss/total_loss': 0.23356879,\n",
            " 'learning_rate': 0.0039903694}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.149s\n",
            "I1103 04:00:08.644868 138844351791744 model_lib_v2.py:705] Step 3600 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13396542,\n",
            " 'Loss/localization_loss': 0.0752559,\n",
            " 'Loss/regularization_loss': 0.08761809,\n",
            " 'Loss/total_loss': 0.29683942,\n",
            " 'learning_rate': 0.003989044}\n",
            "I1103 04:00:08.645269 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.13396542,\n",
            " 'Loss/localization_loss': 0.0752559,\n",
            " 'Loss/regularization_loss': 0.08761809,\n",
            " 'Loss/total_loss': 0.29683942,\n",
            " 'learning_rate': 0.003989044}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.149s\n",
            "I1103 04:00:23.545695 138844351791744 model_lib_v2.py:705] Step 3700 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12039297,\n",
            " 'Loss/localization_loss': 0.049092926,\n",
            " 'Loss/regularization_loss': 0.087598756,\n",
            " 'Loss/total_loss': 0.25708467,\n",
            " 'learning_rate': 0.003987633}\n",
            "I1103 04:00:23.547351 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.12039297,\n",
            " 'Loss/localization_loss': 0.049092926,\n",
            " 'Loss/regularization_loss': 0.087598756,\n",
            " 'Loss/total_loss': 0.25708467,\n",
            " 'learning_rate': 0.003987633}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.150s\n",
            "I1103 04:00:38.518429 138844351791744 model_lib_v2.py:705] Step 3800 per-step time 0.150s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.104747646,\n",
            " 'Loss/localization_loss': 0.040147793,\n",
            " 'Loss/regularization_loss': 0.08757798,\n",
            " 'Loss/total_loss': 0.2324734,\n",
            " 'learning_rate': 0.003986137}\n",
            "I1103 04:00:38.518791 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.104747646,\n",
            " 'Loss/localization_loss': 0.040147793,\n",
            " 'Loss/regularization_loss': 0.08757798,\n",
            " 'Loss/total_loss': 0.2324734,\n",
            " 'learning_rate': 0.003986137}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.148s\n",
            "I1103 04:00:53.338723 138844351791744 model_lib_v2.py:705] Step 3900 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1387104,\n",
            " 'Loss/localization_loss': 0.0316082,\n",
            " 'Loss/regularization_loss': 0.087557964,\n",
            " 'Loss/total_loss': 0.25787657,\n",
            " 'learning_rate': 0.003984556}\n",
            "I1103 04:00:53.339107 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.1387104,\n",
            " 'Loss/localization_loss': 0.0316082,\n",
            " 'Loss/regularization_loss': 0.087557964,\n",
            " 'Loss/total_loss': 0.25787657,\n",
            " 'learning_rate': 0.003984556}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.148s\n",
            "I1103 04:01:08.181409 138844351791744 model_lib_v2.py:705] Step 4000 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05463589,\n",
            " 'Loss/localization_loss': 0.01694644,\n",
            " 'Loss/regularization_loss': 0.087537944,\n",
            " 'Loss/total_loss': 0.15912028,\n",
            " 'learning_rate': 0.00398289}\n",
            "I1103 04:01:08.181787 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.05463589,\n",
            " 'Loss/localization_loss': 0.01694644,\n",
            " 'Loss/regularization_loss': 0.087537944,\n",
            " 'Loss/total_loss': 0.15912028,\n",
            " 'learning_rate': 0.00398289}\n",
            "INFO:tensorflow:Step 4100 per-step time 0.158s\n",
            "I1103 04:01:23.993134 138844351791744 model_lib_v2.py:705] Step 4100 per-step time 0.158s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0755928,\n",
            " 'Loss/localization_loss': 0.034769747,\n",
            " 'Loss/regularization_loss': 0.087518275,\n",
            " 'Loss/total_loss': 0.19788082,\n",
            " 'learning_rate': 0.003981139}\n",
            "I1103 04:01:23.993549 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.0755928,\n",
            " 'Loss/localization_loss': 0.034769747,\n",
            " 'Loss/regularization_loss': 0.087518275,\n",
            " 'Loss/total_loss': 0.19788082,\n",
            " 'learning_rate': 0.003981139}\n",
            "INFO:tensorflow:Step 4200 per-step time 0.150s\n",
            "I1103 04:01:38.919830 138844351791744 model_lib_v2.py:705] Step 4200 per-step time 0.150s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1522058,\n",
            " 'Loss/localization_loss': 0.05551551,\n",
            " 'Loss/regularization_loss': 0.087499164,\n",
            " 'Loss/total_loss': 0.29522046,\n",
            " 'learning_rate': 0.003979303}\n",
            "I1103 04:01:38.920212 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.1522058,\n",
            " 'Loss/localization_loss': 0.05551551,\n",
            " 'Loss/regularization_loss': 0.087499164,\n",
            " 'Loss/total_loss': 0.29522046,\n",
            " 'learning_rate': 0.003979303}\n",
            "INFO:tensorflow:Step 4300 per-step time 0.148s\n",
            "I1103 04:01:53.717980 138844351791744 model_lib_v2.py:705] Step 4300 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06992109,\n",
            " 'Loss/localization_loss': 0.016225543,\n",
            " 'Loss/regularization_loss': 0.08747956,\n",
            " 'Loss/total_loss': 0.1736262,\n",
            " 'learning_rate': 0.0039773826}\n",
            "I1103 04:01:53.718308 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.06992109,\n",
            " 'Loss/localization_loss': 0.016225543,\n",
            " 'Loss/regularization_loss': 0.08747956,\n",
            " 'Loss/total_loss': 0.1736262,\n",
            " 'learning_rate': 0.0039773826}\n",
            "INFO:tensorflow:Step 4400 per-step time 0.148s\n",
            "I1103 04:02:08.494820 138844351791744 model_lib_v2.py:705] Step 4400 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.104614735,\n",
            " 'Loss/localization_loss': 0.045331977,\n",
            " 'Loss/regularization_loss': 0.08745861,\n",
            " 'Loss/total_loss': 0.23740533,\n",
            " 'learning_rate': 0.003975377}\n",
            "I1103 04:02:08.495172 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.104614735,\n",
            " 'Loss/localization_loss': 0.045331977,\n",
            " 'Loss/regularization_loss': 0.08745861,\n",
            " 'Loss/total_loss': 0.23740533,\n",
            " 'learning_rate': 0.003975377}\n",
            "INFO:tensorflow:Step 4500 per-step time 0.148s\n",
            "I1103 04:02:23.302322 138844351791744 model_lib_v2.py:705] Step 4500 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18627019,\n",
            " 'Loss/localization_loss': 0.09105147,\n",
            " 'Loss/regularization_loss': 0.08743876,\n",
            " 'Loss/total_loss': 0.36476043,\n",
            " 'learning_rate': 0.0039732866}\n",
            "I1103 04:02:23.302652 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.18627019,\n",
            " 'Loss/localization_loss': 0.09105147,\n",
            " 'Loss/regularization_loss': 0.08743876,\n",
            " 'Loss/total_loss': 0.36476043,\n",
            " 'learning_rate': 0.0039732866}\n",
            "INFO:tensorflow:Step 4600 per-step time 0.149s\n",
            "I1103 04:02:38.207339 138844351791744 model_lib_v2.py:705] Step 4600 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10900464,\n",
            " 'Loss/localization_loss': 0.072889455,\n",
            " 'Loss/regularization_loss': 0.08741924,\n",
            " 'Loss/total_loss': 0.26931334,\n",
            " 'learning_rate': 0.0039711124}\n",
            "I1103 04:02:38.207648 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.10900464,\n",
            " 'Loss/localization_loss': 0.072889455,\n",
            " 'Loss/regularization_loss': 0.08741924,\n",
            " 'Loss/total_loss': 0.26931334,\n",
            " 'learning_rate': 0.0039711124}\n",
            "INFO:tensorflow:Step 4700 per-step time 0.149s\n",
            "I1103 04:02:53.151354 138844351791744 model_lib_v2.py:705] Step 4700 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10870711,\n",
            " 'Loss/localization_loss': 0.021010138,\n",
            " 'Loss/regularization_loss': 0.08739974,\n",
            " 'Loss/total_loss': 0.21711698,\n",
            " 'learning_rate': 0.003968853}\n",
            "I1103 04:02:53.151698 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.10870711,\n",
            " 'Loss/localization_loss': 0.021010138,\n",
            " 'Loss/regularization_loss': 0.08739974,\n",
            " 'Loss/total_loss': 0.21711698,\n",
            " 'learning_rate': 0.003968853}\n",
            "INFO:tensorflow:Step 4800 per-step time 0.147s\n",
            "I1103 04:03:07.873479 138844351791744 model_lib_v2.py:705] Step 4800 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08707223,\n",
            " 'Loss/localization_loss': 0.028332831,\n",
            " 'Loss/regularization_loss': 0.08737902,\n",
            " 'Loss/total_loss': 0.20278409,\n",
            " 'learning_rate': 0.00396651}\n",
            "I1103 04:03:07.873784 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.08707223,\n",
            " 'Loss/localization_loss': 0.028332831,\n",
            " 'Loss/regularization_loss': 0.08737902,\n",
            " 'Loss/total_loss': 0.20278409,\n",
            " 'learning_rate': 0.00396651}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.148s\n",
            "I1103 04:03:22.629668 138844351791744 model_lib_v2.py:705] Step 4900 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10697189,\n",
            " 'Loss/localization_loss': 0.024465628,\n",
            " 'Loss/regularization_loss': 0.087359,\n",
            " 'Loss/total_loss': 0.21879652,\n",
            " 'learning_rate': 0.0039640823}\n",
            "I1103 04:03:22.629984 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.10697189,\n",
            " 'Loss/localization_loss': 0.024465628,\n",
            " 'Loss/regularization_loss': 0.087359,\n",
            " 'Loss/total_loss': 0.21879652,\n",
            " 'learning_rate': 0.0039640823}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.148s\n",
            "I1103 04:03:37.451366 138844351791744 model_lib_v2.py:705] Step 5000 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09046404,\n",
            " 'Loss/localization_loss': 0.02557177,\n",
            " 'Loss/regularization_loss': 0.08733919,\n",
            " 'Loss/total_loss': 0.20337501,\n",
            " 'learning_rate': 0.0039615706}\n",
            "I1103 04:03:37.451709 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.09046404,\n",
            " 'Loss/localization_loss': 0.02557177,\n",
            " 'Loss/regularization_loss': 0.08733919,\n",
            " 'Loss/total_loss': 0.20337501,\n",
            " 'learning_rate': 0.0039615706}\n",
            "INFO:tensorflow:Step 5100 per-step time 0.148s\n",
            "I1103 04:03:52.232032 138844351791744 model_lib_v2.py:705] Step 5100 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0868274,\n",
            " 'Loss/localization_loss': 0.031719238,\n",
            " 'Loss/regularization_loss': 0.087321214,\n",
            " 'Loss/total_loss': 0.20586786,\n",
            " 'learning_rate': 0.003958975}\n",
            "I1103 04:03:52.232377 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.0868274,\n",
            " 'Loss/localization_loss': 0.031719238,\n",
            " 'Loss/regularization_loss': 0.087321214,\n",
            " 'Loss/total_loss': 0.20586786,\n",
            " 'learning_rate': 0.003958975}\n",
            "INFO:tensorflow:Step 5200 per-step time 0.148s\n",
            "I1103 04:04:07.052385 138844351791744 model_lib_v2.py:705] Step 5200 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08970956,\n",
            " 'Loss/localization_loss': 0.024518913,\n",
            " 'Loss/regularization_loss': 0.0873021,\n",
            " 'Loss/total_loss': 0.20153058,\n",
            " 'learning_rate': 0.0039562955}\n",
            "I1103 04:04:07.052661 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.08970956,\n",
            " 'Loss/localization_loss': 0.024518913,\n",
            " 'Loss/regularization_loss': 0.0873021,\n",
            " 'Loss/total_loss': 0.20153058,\n",
            " 'learning_rate': 0.0039562955}\n",
            "INFO:tensorflow:Step 5300 per-step time 0.148s\n",
            "I1103 04:04:21.841971 138844351791744 model_lib_v2.py:705] Step 5300 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04840204,\n",
            " 'Loss/localization_loss': 0.01609718,\n",
            " 'Loss/regularization_loss': 0.08728268,\n",
            " 'Loss/total_loss': 0.1517819,\n",
            " 'learning_rate': 0.003953532}\n",
            "I1103 04:04:21.842302 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.04840204,\n",
            " 'Loss/localization_loss': 0.01609718,\n",
            " 'Loss/regularization_loss': 0.08728268,\n",
            " 'Loss/total_loss': 0.1517819,\n",
            " 'learning_rate': 0.003953532}\n",
            "INFO:tensorflow:Step 5400 per-step time 0.148s\n",
            "I1103 04:04:36.636186 138844351791744 model_lib_v2.py:705] Step 5400 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12533349,\n",
            " 'Loss/localization_loss': 0.032695875,\n",
            " 'Loss/regularization_loss': 0.08726161,\n",
            " 'Loss/total_loss': 0.24529096,\n",
            " 'learning_rate': 0.003950685}\n",
            "I1103 04:04:36.636502 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.12533349,\n",
            " 'Loss/localization_loss': 0.032695875,\n",
            " 'Loss/regularization_loss': 0.08726161,\n",
            " 'Loss/total_loss': 0.24529096,\n",
            " 'learning_rate': 0.003950685}\n",
            "INFO:tensorflow:Step 5500 per-step time 0.147s\n",
            "I1103 04:04:51.377432 138844351791744 model_lib_v2.py:705] Step 5500 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10253192,\n",
            " 'Loss/localization_loss': 0.037232794,\n",
            " 'Loss/regularization_loss': 0.08724206,\n",
            " 'Loss/total_loss': 0.22700676,\n",
            " 'learning_rate': 0.003947754}\n",
            "I1103 04:04:51.377928 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.10253192,\n",
            " 'Loss/localization_loss': 0.037232794,\n",
            " 'Loss/regularization_loss': 0.08724206,\n",
            " 'Loss/total_loss': 0.22700676,\n",
            " 'learning_rate': 0.003947754}\n",
            "INFO:tensorflow:Step 5600 per-step time 0.150s\n",
            "I1103 04:05:06.351196 138844351791744 model_lib_v2.py:705] Step 5600 per-step time 0.150s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07907548,\n",
            " 'Loss/localization_loss': 0.032018345,\n",
            " 'Loss/regularization_loss': 0.08722124,\n",
            " 'Loss/total_loss': 0.19831505,\n",
            " 'learning_rate': 0.00394474}\n",
            "I1103 04:05:06.351583 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.07907548,\n",
            " 'Loss/localization_loss': 0.032018345,\n",
            " 'Loss/regularization_loss': 0.08722124,\n",
            " 'Loss/total_loss': 0.19831505,\n",
            " 'learning_rate': 0.00394474}\n",
            "INFO:tensorflow:Step 5700 per-step time 0.149s\n",
            "I1103 04:05:21.250306 138844351791744 model_lib_v2.py:705] Step 5700 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15944904,\n",
            " 'Loss/localization_loss': 0.053254224,\n",
            " 'Loss/regularization_loss': 0.08720119,\n",
            " 'Loss/total_loss': 0.29990447,\n",
            " 'learning_rate': 0.0039416426}\n",
            "I1103 04:05:21.250688 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.15944904,\n",
            " 'Loss/localization_loss': 0.053254224,\n",
            " 'Loss/regularization_loss': 0.08720119,\n",
            " 'Loss/total_loss': 0.29990447,\n",
            " 'learning_rate': 0.0039416426}\n",
            "INFO:tensorflow:Step 5800 per-step time 0.150s\n",
            "I1103 04:05:36.217550 138844351791744 model_lib_v2.py:705] Step 5800 per-step time 0.150s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.054064427,\n",
            " 'Loss/localization_loss': 0.012701981,\n",
            " 'Loss/regularization_loss': 0.08718085,\n",
            " 'Loss/total_loss': 0.15394726,\n",
            " 'learning_rate': 0.003938462}\n",
            "I1103 04:05:36.219226 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.054064427,\n",
            " 'Loss/localization_loss': 0.012701981,\n",
            " 'Loss/regularization_loss': 0.08718085,\n",
            " 'Loss/total_loss': 0.15394726,\n",
            " 'learning_rate': 0.003938462}\n",
            "INFO:tensorflow:Step 5900 per-step time 0.150s\n",
            "I1103 04:05:51.224233 138844351791744 model_lib_v2.py:705] Step 5900 per-step time 0.150s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10789544,\n",
            " 'Loss/localization_loss': 0.034368828,\n",
            " 'Loss/regularization_loss': 0.08716001,\n",
            " 'Loss/total_loss': 0.2294243,\n",
            " 'learning_rate': 0.0039351983}\n",
            "I1103 04:05:51.224617 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.10789544,\n",
            " 'Loss/localization_loss': 0.034368828,\n",
            " 'Loss/regularization_loss': 0.08716001,\n",
            " 'Loss/total_loss': 0.2294243,\n",
            " 'learning_rate': 0.0039351983}\n",
            "INFO:tensorflow:Step 6000 per-step time 0.149s\n",
            "I1103 04:06:06.124690 138844351791744 model_lib_v2.py:705] Step 6000 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06950226,\n",
            " 'Loss/localization_loss': 0.027502242,\n",
            " 'Loss/regularization_loss': 0.08713872,\n",
            " 'Loss/total_loss': 0.18414322,\n",
            " 'learning_rate': 0.0039318516}\n",
            "I1103 04:06:06.125039 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.06950226,\n",
            " 'Loss/localization_loss': 0.027502242,\n",
            " 'Loss/regularization_loss': 0.08713872,\n",
            " 'Loss/total_loss': 0.18414322,\n",
            " 'learning_rate': 0.0039318516}\n",
            "INFO:tensorflow:Step 6100 per-step time 0.158s\n",
            "I1103 04:06:21.912642 138844351791744 model_lib_v2.py:705] Step 6100 per-step time 0.158s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12614878,\n",
            " 'Loss/localization_loss': 0.04182925,\n",
            " 'Loss/regularization_loss': 0.08711853,\n",
            " 'Loss/total_loss': 0.25509655,\n",
            " 'learning_rate': 0.0039284225}\n",
            "I1103 04:06:21.913016 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.12614878,\n",
            " 'Loss/localization_loss': 0.04182925,\n",
            " 'Loss/regularization_loss': 0.08711853,\n",
            " 'Loss/total_loss': 0.25509655,\n",
            " 'learning_rate': 0.0039284225}\n",
            "INFO:tensorflow:Step 6200 per-step time 0.148s\n",
            "I1103 04:06:36.696834 138844351791744 model_lib_v2.py:705] Step 6200 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1399272,\n",
            " 'Loss/localization_loss': 0.050037403,\n",
            " 'Loss/regularization_loss': 0.08709695,\n",
            " 'Loss/total_loss': 0.27706155,\n",
            " 'learning_rate': 0.003924911}\n",
            "I1103 04:06:36.699198 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.1399272,\n",
            " 'Loss/localization_loss': 0.050037403,\n",
            " 'Loss/regularization_loss': 0.08709695,\n",
            " 'Loss/total_loss': 0.27706155,\n",
            " 'learning_rate': 0.003924911}\n",
            "INFO:tensorflow:Step 6300 per-step time 0.148s\n",
            "I1103 04:06:51.521443 138844351791744 model_lib_v2.py:705] Step 6300 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08487281,\n",
            " 'Loss/localization_loss': 0.18161471,\n",
            " 'Loss/regularization_loss': 0.08707697,\n",
            " 'Loss/total_loss': 0.3535645,\n",
            " 'learning_rate': 0.0039213165}\n",
            "I1103 04:06:51.521766 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.08487281,\n",
            " 'Loss/localization_loss': 0.18161471,\n",
            " 'Loss/regularization_loss': 0.08707697,\n",
            " 'Loss/total_loss': 0.3535645,\n",
            " 'learning_rate': 0.0039213165}\n",
            "INFO:tensorflow:Step 6400 per-step time 0.149s\n",
            "I1103 04:07:06.430046 138844351791744 model_lib_v2.py:705] Step 6400 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07357293,\n",
            " 'Loss/localization_loss': 0.02605294,\n",
            " 'Loss/regularization_loss': 0.08705823,\n",
            " 'Loss/total_loss': 0.1866841,\n",
            " 'learning_rate': 0.0039176396}\n",
            "I1103 04:07:06.430384 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.07357293,\n",
            " 'Loss/localization_loss': 0.02605294,\n",
            " 'Loss/regularization_loss': 0.08705823,\n",
            " 'Loss/total_loss': 0.1866841,\n",
            " 'learning_rate': 0.0039176396}\n",
            "INFO:tensorflow:Step 6500 per-step time 0.147s\n",
            "I1103 04:07:21.166774 138844351791744 model_lib_v2.py:705] Step 6500 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15804681,\n",
            " 'Loss/localization_loss': 0.07166857,\n",
            " 'Loss/regularization_loss': 0.08703741,\n",
            " 'Loss/total_loss': 0.3167528,\n",
            " 'learning_rate': 0.003913881}\n",
            "I1103 04:07:21.167115 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.15804681,\n",
            " 'Loss/localization_loss': 0.07166857,\n",
            " 'Loss/regularization_loss': 0.08703741,\n",
            " 'Loss/total_loss': 0.3167528,\n",
            " 'learning_rate': 0.003913881}\n",
            "INFO:tensorflow:Step 6600 per-step time 0.147s\n",
            "I1103 04:07:35.897166 138844351791744 model_lib_v2.py:705] Step 6600 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06194021,\n",
            " 'Loss/localization_loss': 0.021156337,\n",
            " 'Loss/regularization_loss': 0.08701681,\n",
            " 'Loss/total_loss': 0.17011335,\n",
            " 'learning_rate': 0.00391004}\n",
            "I1103 04:07:35.897555 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.06194021,\n",
            " 'Loss/localization_loss': 0.021156337,\n",
            " 'Loss/regularization_loss': 0.08701681,\n",
            " 'Loss/total_loss': 0.17011335,\n",
            " 'learning_rate': 0.00391004}\n",
            "INFO:tensorflow:Step 6700 per-step time 0.147s\n",
            "I1103 04:07:50.588893 138844351791744 model_lib_v2.py:705] Step 6700 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08775314,\n",
            " 'Loss/localization_loss': 0.033474777,\n",
            " 'Loss/regularization_loss': 0.086997315,\n",
            " 'Loss/total_loss': 0.20822524,\n",
            " 'learning_rate': 0.0039061175}\n",
            "I1103 04:07:50.589210 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.08775314,\n",
            " 'Loss/localization_loss': 0.033474777,\n",
            " 'Loss/regularization_loss': 0.086997315,\n",
            " 'Loss/total_loss': 0.20822524,\n",
            " 'learning_rate': 0.0039061175}\n",
            "INFO:tensorflow:Step 6800 per-step time 0.148s\n",
            "I1103 04:08:05.425204 138844351791744 model_lib_v2.py:705] Step 6800 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15631759,\n",
            " 'Loss/localization_loss': 0.046846725,\n",
            " 'Loss/regularization_loss': 0.086977184,\n",
            " 'Loss/total_loss': 0.2901415,\n",
            " 'learning_rate': 0.003902113}\n",
            "I1103 04:08:05.425508 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.15631759,\n",
            " 'Loss/localization_loss': 0.046846725,\n",
            " 'Loss/regularization_loss': 0.086977184,\n",
            " 'Loss/total_loss': 0.2901415,\n",
            " 'learning_rate': 0.003902113}\n",
            "INFO:tensorflow:Step 6900 per-step time 0.149s\n",
            "I1103 04:08:20.284180 138844351791744 model_lib_v2.py:705] Step 6900 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.120638445,\n",
            " 'Loss/localization_loss': 0.034040842,\n",
            " 'Loss/regularization_loss': 0.086956784,\n",
            " 'Loss/total_loss': 0.24163607,\n",
            " 'learning_rate': 0.0038980276}\n",
            "I1103 04:08:20.284500 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.120638445,\n",
            " 'Loss/localization_loss': 0.034040842,\n",
            " 'Loss/regularization_loss': 0.086956784,\n",
            " 'Loss/total_loss': 0.24163607,\n",
            " 'learning_rate': 0.0038980276}\n",
            "INFO:tensorflow:Step 7000 per-step time 0.148s\n",
            "I1103 04:08:35.052818 138844351791744 model_lib_v2.py:705] Step 7000 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09714627,\n",
            " 'Loss/localization_loss': 0.046088457,\n",
            " 'Loss/regularization_loss': 0.08693561,\n",
            " 'Loss/total_loss': 0.23017034,\n",
            " 'learning_rate': 0.0038938606}\n",
            "I1103 04:08:35.053140 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.09714627,\n",
            " 'Loss/localization_loss': 0.046088457,\n",
            " 'Loss/regularization_loss': 0.08693561,\n",
            " 'Loss/total_loss': 0.23017034,\n",
            " 'learning_rate': 0.0038938606}\n",
            "INFO:tensorflow:Step 7100 per-step time 0.149s\n",
            "I1103 04:08:49.950546 138844351791744 model_lib_v2.py:705] Step 7100 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06017084,\n",
            " 'Loss/localization_loss': 0.021035869,\n",
            " 'Loss/regularization_loss': 0.086915694,\n",
            " 'Loss/total_loss': 0.16812241,\n",
            " 'learning_rate': 0.0038896124}\n",
            "I1103 04:08:49.951034 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.06017084,\n",
            " 'Loss/localization_loss': 0.021035869,\n",
            " 'Loss/regularization_loss': 0.086915694,\n",
            " 'Loss/total_loss': 0.16812241,\n",
            " 'learning_rate': 0.0038896124}\n",
            "INFO:tensorflow:Step 7200 per-step time 0.147s\n",
            "I1103 04:09:04.660188 138844351791744 model_lib_v2.py:705] Step 7200 per-step time 0.147s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.110901825,\n",
            " 'Loss/localization_loss': 0.064554654,\n",
            " 'Loss/regularization_loss': 0.08689735,\n",
            " 'Loss/total_loss': 0.26235384,\n",
            " 'learning_rate': 0.0038852831}\n",
            "I1103 04:09:04.660564 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.110901825,\n",
            " 'Loss/localization_loss': 0.064554654,\n",
            " 'Loss/regularization_loss': 0.08689735,\n",
            " 'Loss/total_loss': 0.26235384,\n",
            " 'learning_rate': 0.0038852831}\n",
            "INFO:tensorflow:Step 7300 per-step time 0.151s\n",
            "I1103 04:09:19.776971 138844351791744 model_lib_v2.py:705] Step 7300 per-step time 0.151s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06772982,\n",
            " 'Loss/localization_loss': 0.023887763,\n",
            " 'Loss/regularization_loss': 0.08687687,\n",
            " 'Loss/total_loss': 0.17849445,\n",
            " 'learning_rate': 0.0038808733}\n",
            "I1103 04:09:19.777387 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.06772982,\n",
            " 'Loss/localization_loss': 0.023887763,\n",
            " 'Loss/regularization_loss': 0.08687687,\n",
            " 'Loss/total_loss': 0.17849445,\n",
            " 'learning_rate': 0.0038808733}\n",
            "INFO:tensorflow:Step 7400 per-step time 0.149s\n",
            "I1103 04:09:34.666183 138844351791744 model_lib_v2.py:705] Step 7400 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10923881,\n",
            " 'Loss/localization_loss': 0.053001918,\n",
            " 'Loss/regularization_loss': 0.08685737,\n",
            " 'Loss/total_loss': 0.24909809,\n",
            " 'learning_rate': 0.003876383}\n",
            "I1103 04:09:34.666559 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.10923881,\n",
            " 'Loss/localization_loss': 0.053001918,\n",
            " 'Loss/regularization_loss': 0.08685737,\n",
            " 'Loss/total_loss': 0.24909809,\n",
            " 'learning_rate': 0.003876383}\n",
            "INFO:tensorflow:Step 7500 per-step time 0.148s\n",
            "I1103 04:09:49.516653 138844351791744 model_lib_v2.py:705] Step 7500 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06461268,\n",
            " 'Loss/localization_loss': 0.022738263,\n",
            " 'Loss/regularization_loss': 0.086836964,\n",
            " 'Loss/total_loss': 0.1741879,\n",
            " 'learning_rate': 0.003871812}\n",
            "I1103 04:09:49.517174 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.06461268,\n",
            " 'Loss/localization_loss': 0.022738263,\n",
            " 'Loss/regularization_loss': 0.086836964,\n",
            " 'Loss/total_loss': 0.1741879,\n",
            " 'learning_rate': 0.003871812}\n",
            "INFO:tensorflow:Step 7600 per-step time 0.149s\n",
            "I1103 04:10:04.404873 138844351791744 model_lib_v2.py:705] Step 7600 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.093090385,\n",
            " 'Loss/localization_loss': 0.041915372,\n",
            " 'Loss/regularization_loss': 0.08681589,\n",
            " 'Loss/total_loss': 0.22182165,\n",
            " 'learning_rate': 0.003867161}\n",
            "I1103 04:10:04.406249 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.093090385,\n",
            " 'Loss/localization_loss': 0.041915372,\n",
            " 'Loss/regularization_loss': 0.08681589,\n",
            " 'Loss/total_loss': 0.22182165,\n",
            " 'learning_rate': 0.003867161}\n",
            "INFO:tensorflow:Step 7700 per-step time 0.149s\n",
            "I1103 04:10:19.319996 138844351791744 model_lib_v2.py:705] Step 7700 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.059097935,\n",
            " 'Loss/localization_loss': 0.012434508,\n",
            " 'Loss/regularization_loss': 0.086796254,\n",
            " 'Loss/total_loss': 0.1583287,\n",
            " 'learning_rate': 0.00386243}\n",
            "I1103 04:10:19.320404 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.059097935,\n",
            " 'Loss/localization_loss': 0.012434508,\n",
            " 'Loss/regularization_loss': 0.086796254,\n",
            " 'Loss/total_loss': 0.1583287,\n",
            " 'learning_rate': 0.00386243}\n",
            "INFO:tensorflow:Step 7800 per-step time 0.149s\n",
            "I1103 04:10:34.149223 138844351791744 model_lib_v2.py:705] Step 7800 per-step time 0.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.060211644,\n",
            " 'Loss/localization_loss': 0.050511252,\n",
            " 'Loss/regularization_loss': 0.0867751,\n",
            " 'Loss/total_loss': 0.197498,\n",
            " 'learning_rate': 0.0038576191}\n",
            "I1103 04:10:34.149551 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.060211644,\n",
            " 'Loss/localization_loss': 0.050511252,\n",
            " 'Loss/regularization_loss': 0.0867751,\n",
            " 'Loss/total_loss': 0.197498,\n",
            " 'learning_rate': 0.0038576191}\n",
            "INFO:tensorflow:Step 7900 per-step time 0.148s\n",
            "I1103 04:10:48.957255 138844351791744 model_lib_v2.py:705] Step 7900 per-step time 0.148s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07530194,\n",
            " 'Loss/localization_loss': 0.024358792,\n",
            " 'Loss/regularization_loss': 0.086754665,\n",
            " 'Loss/total_loss': 0.1864154,\n",
            " 'learning_rate': 0.003852729}\n",
            "I1103 04:10:48.957578 138844351791744 model_lib_v2.py:708] {'Loss/classification_loss': 0.07530194,\n",
            " 'Loss/localization_loss': 0.024358792,\n",
            " 'Loss/regularization_loss': 0.086754665,\n",
            " 'Loss/total_loss': 0.1864154,\n",
            " 'learning_rate': 0.003852729}\n"
          ]
        }
      ],
      "source": [
        "!rm -rf {HOMEFOLDER}training_progress\n",
        "# Run training!\n",
        "!python {HOMEFOLDER}models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --checkpoint_every_n={checkpoint_every} \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_workers=2 \\\n",
        "    --sample_1_of_n_eval_examples=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHxbX4ZpzXIv"
      },
      "source": [
        "Feel free to stop training early. Check the 'training_progress' folder to see all training checkpoints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPg8oMnQDYKl"
      },
      "source": [
        "# 5.&nbsp;Convert Model to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaUU8tBlHifd"
      },
      "outputs": [],
      "source": [
        "#remove final output folder if it exists\n",
        "if os.path.exists(FINALOUTPUTFOLDER) and os.path.isdir(FINALOUTPUTFOLDER):\n",
        "  shutil.rmtree(FINALOUTPUTFOLDER)\n",
        "\n",
        "# Make a directory to store the trained TFLite model\n",
        "!mkdir {FINALOUTPUTFOLDER}\n",
        "print(FINALOUTPUTFOLDER)\n",
        "# Export graph\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = HOMEFOLDER+'training_progress'\n",
        "exporter_path = HOMEFOLDER+'models/research/object_detection/export_tflite_graph_tf2.py'\n",
        "output_directory = FINALOUTPUTFOLDER\n",
        "\n",
        "!python $exporter_path \\\n",
        "    --trained_checkpoint_dir $last_model_path \\\n",
        "    --output_directory $output_directory \\\n",
        "    --pipeline_config_path $pipeline_file\n",
        "\n",
        "# Convert to .tflite Flatbuffer\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "model_path_32bit = FINALOUTPUTFOLDER+'/limelight_neural_detector_32bit.tflite'\n",
        "with open(model_path_32bit, 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}\n",
        "!cp {HOMEFOLDER}models/mymodel/pipeline_file.config {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqahbHU1suBi"
      },
      "outputs": [],
      "source": [
        "# Export graph\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = HOMEFOLDER+'training_progress'\n",
        "exporter_path = HOMEFOLDER+'models/research/object_detection/export_tflite_graph_tf2.py'\n",
        "output_directory = FINALOUTPUTFOLDER\n",
        "\n",
        "!python $exporter_path \\\n",
        "    --trained_checkpoint_dir $last_model_path \\\n",
        "    --output_directory $output_directory \\\n",
        "    --pipeline_config_path $pipeline_file\n",
        "\n",
        "# Convert to .tflite Flatbuffer\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "model_path_32bit = FINALOUTPUTFOLDER+'/limelight_neural_detector_32bit.tflite'\n",
        "with open(model_path_32bit, 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTyqlXFTJ0Uv"
      },
      "source": [
        "# 6. Quantize model\n",
        "The \"TFLiteConverter\" module will perform [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) on the model. To quantize the model, we need to provide a set of example images. We will extract 100 images from the training tfrecord and place said images into the \"extracted_samples\" folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSNZtfj_k3NP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "def extract_images_from_tfrecord(tfrecord_path, output_folder, num_samples=100):\n",
        "    # Make sure the output directory exists\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Initialize a counter for the number of images saved\n",
        "    saved_images = 0\n",
        "\n",
        "    # Read the TFRecord file\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    for raw_record in raw_dataset.take(num_samples):\n",
        "        example = tf.train.Example()\n",
        "        example.ParseFromString(raw_record.numpy())\n",
        "\n",
        "        # Extract the image data (change 'image/encoded' if necessary)\n",
        "        image_data = example.features.feature['image/encoded'].bytes_list.value[0]\n",
        "\n",
        "        # Decode the image data and save as a file\n",
        "        image = Image.open(io.BytesIO(image_data))\n",
        "        image.save(os.path.join(output_folder, f'image_{saved_images}.png'))\n",
        "\n",
        "        saved_images += 1\n",
        "        if saved_images >= num_samples:\n",
        "            break\n",
        "\n",
        "    print(f\"Extracted {saved_images} images to {output_folder}\")\n",
        "\n",
        "# Set the path to your TFRecord file and the output directory\n",
        "tfrecord_path = train_record_fname\n",
        "extracted_sample_folder = HOMEFOLDER+'extracted_samples'\n",
        "\n",
        "#remove sample folder if it exists\n",
        "if os.path.exists(extracted_sample_folder) and os.path.isdir(extracted_sample_folder):\n",
        "  shutil.rmtree(extracted_sample_folder)\n",
        "\n",
        "# Extract images\n",
        "extract_images_from_tfrecord(tfrecord_path, extracted_sample_folder)\n",
        "\n",
        "\n",
        "# Get list of all images in train directory\n",
        "from google.cloud import storage\n",
        "import glob\n",
        "\n",
        "quant_image_list=[]\n",
        "if(MLENVIRONMENT==\"COLAB\"):\n",
        "\n",
        "    jpg_file_list = glob.glob(extracted_sample_folder + '/*.jpg')\n",
        "    jpeg_file_list = glob.glob(extracted_sample_folder + '/*.jpeg')\n",
        "    JPG_file_list = glob.glob(extracted_sample_folder + '/*.JPG')\n",
        "    png_file_list = glob.glob(extracted_sample_folder + '/*.png')\n",
        "    bmp_file_list = glob.glob(extracted_sample_folder + '/*.bmp')\n",
        "    quant_image_list = jpg_file_list + JPG_file_list + png_file_list + bmp_file_list\n",
        "\n",
        "print(\"pulling samples from \" + extracted_sample_folder)\n",
        "print(\"samples: \" + str(len(quant_image_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORzx0XRErSLV"
      },
      "outputs": [],
      "source": [
        "# A generator that provides a representative dataset\n",
        "# Code modified from https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb\n",
        "\n",
        "# First, get input details for model so we know how to preprocess images\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path_32bit)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "height = input_details[0]['shape'][1]\n",
        "width = input_details[0]['shape'][2]\n",
        "\n",
        "import random\n",
        "\n",
        "def representative_data_gen():\n",
        "  dataset_list = quant_image_list\n",
        "  quant_num = 300\n",
        "  for i in range(quant_num):\n",
        "    pick_me = random.choice(dataset_list)\n",
        "    print(pick_me)\n",
        "    image = tf.io.read_file(pick_me)\n",
        "\n",
        "    if pick_me.endswith('.jpg') or pick_me.endswith('.JPG') or pick_me.endswith('.jpeg'):\n",
        "      image = tf.io.decode_jpeg(image, channels=3)\n",
        "    elif pick_me.endswith('.png'):\n",
        "      image = tf.io.decode_png(image, channels=3)\n",
        "    elif pick_me.endswith('.bmp'):\n",
        "      image = tf.io.decode_bmp(image, channels=3)\n",
        "\n",
        "    image = tf.image.resize(image, [width, height])  # TO DO: Replace 300s with an automatic way of reading network input size\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    yield [image]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtu98mzebEj"
      },
      "source": [
        "Finally, we'll initialize the TFLiteConverter module, point it at the TFLite graph we generated in Step 6, and provide it with the representative dataset generator function we created in the previous code block. We'll configure the converter to quantize the model's weight values to INT8 format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox0bGDWds_Ce"
      },
      "outputs": [],
      "source": [
        "# Initialize converter module\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "print(\"initialized converter\")\n",
        "# This enables quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# This sets the representative dataset for quantization\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# This ensures that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "# These set the input tensors to uint8 and output tensors to float32\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.float32\n",
        "print(\"begin conversion\")\n",
        "tflite_model = converter.convert()\n",
        "print(\"conversion complete\")\n",
        "\n",
        "with open(FINALOUTPUTFOLDER+'/limelight_neural_detector_8bit.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFsuasvxFHo8"
      },
      "source": [
        "# 7. Compile Model for Limelight & Download\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peawOI_z0DHt"
      },
      "source": [
        "Install Coral Compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUd_SNC0JSq0"
      },
      "outputs": [],
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "! sudo apt-get update\n",
        "! sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usfmdtSiJuuC"
      },
      "source": [
        "Compile the previously-generated 8-bit model for Google Coral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mULCY0nb0ahH"
      },
      "outputs": [],
      "source": [
        "!cd {FINALOUTPUTFOLDER} && pwd && edgetpu_compiler limelight_neural_detector_8bit.tflite && pwd && mv limelight_neural_detector_8bit_edgetpu.tflite limelight_neural_detector_coral.tflite && rm limelight_neural_detector_8bit_edgetpu.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqGy2FgzKomN"
      },
      "source": [
        "Zip models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nCdUouYJjQM"
      },
      "outputs": [],
      "source": [
        "!rm {HOMEFOLDER}limelight_detectors.zip\n",
        "!zip -r {HOMEFOLDER}limelight_detectors.zip {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHgbpkQue-ZR"
      },
      "source": [
        "Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmjqvKuuK8ZR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(HOMEFOLDER+'limelight_detectors.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "05N8FeXHcQp3",
        "xmROIG9zaS9G",
        "eGEUZYAMEZ6f",
        "-19zML6oEO7l",
        "kPg8oMnQDYKl",
        "VTyqlXFTJ0Uv",
        "XFsuasvxFHo8"
      ],
      "gpuClass": "premium",
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "dac6b1a68a930bf8a24417228a96ab80b19f2aa97bc2d428affc356154b4740f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}